# 高效训练&模型压缩

> https://blog.csdn.net/yjw123456/article/details/127059596

## 背景介绍

预训练语言模型以每年十倍的速度增大，越大的模型往往表现出更好的性能；
但为了训练这些模型耗费也越来越昂贵，训练代码变得更复杂。

我们希望让训练过程变得更加简单，训练变得更高效，并且训练更加廉价。

首先我们要分析GPU内存；其次理解在多张显卡之间的合作模式是怎样的。