# Real-time Visual-Inertial Odometry for Event Cameras using Keyframe-based Nonlinear Optimization

## 摘要

事件相机是一种受生物启发的视觉传感器，可输出像素级的亮度变化，而不是标准的强度帧。与标准相机相比，它们具有明显的优势，即动态范围极高、无运动模糊以及微秒级的延迟。我们为这类相机提出了一种新颖、精确、紧密耦合的视觉-惯性里程测量管道，利用其出色的特性，在高速运动或高动态范围场景等具有挑战性的条件下估计相机的自我运动。该方法通过时间跟踪一组特征（在图像平面上提取）。为此，我们考虑重叠时空窗口中的事件，并利用当前摄像机运动和场景结构对其进行对齐，从而得到运动补偿事件帧。然后，我们将这些特征轨迹结合到基于关键帧的视觉惯性里程测量算法中，该算法基于非线性优化来估计摄像机的 6-DOF 姿态、速度和 IMU 偏差。我们在公共事件相机数据集上对所提出的方法进行了定量评估，结果表明该方法明显优于最先进的方法，同时计算效率更高：我们的管道在笔记本电脑甚至智能手机处理器上的运行速度远远超过实时运行速度。此外，我们还在大规模数据集和通过以 850 度/秒的速度旋转拴在绳索上的事件相机记录的超高速数据集上，定性地展示了我们管道的准确性和鲁棒性。

## 引文

活动摄像机，如动态视觉传感器（DVS）[16]，工作方式与传统摄像机非常不同。它们具有独立的像素，仅在场景中发生亮度变化时才发送信息（称为"事件"）。因此，输出不是强度图像，而是微秒分辨率的异步事件流，其中每个事件由其时空坐标和亮度变化的符号（即，无强度）。与标准摄像机相比，活动摄像机具有许多优势：延迟时间为微秒量级，功耗低，动态范围非常高（130 dB，而标准摄像机为60 dB）。最重要的是，由于所有像素都是独立的，因此这种传感器不会受到运动模糊的影响。

从**惯性测量单元(IMU)的图像和测量值组合中**估计传感器的自我运动的任务称为视觉惯性里程计(VIO)，在各种领域都有重要的应用，例如增强/虚拟现实(AR/VR)应用。VIO在过去的几十年里得到了深入的研究，今天已经是一个成熟的研究领域[4]。最先进的VIO管道显示了令人印象深刻的大规模跟踪结果，总体漂移低于移动距离的0.5%([15]、[6])。然而，VIO在许多情况下仍然失败，例如高速运动或高动态范围场景。在第一种情况下，**图像上的大量运动模糊破坏了视觉信息**，迫使管道依赖于IMU的集成，导致大量累积的漂移1。在第二种情况下，由于标准相机的动态范围有限，图像上的大片区域要么曝光过度，要么曝光不足，这大大减少了可利用的信息量。正是在这些具有挑战性的场景中，事件摄像机的上述优势可以被利用来产生准确和稳健的自我运动估计。

## 相关工作

在过去的十年中，许多研究都在考虑使用**事件摄像机进行自我运动估计**。早期的工作主要集中在解决该问题的局限性和较为简单的实例：[5]、[11]、[9] 和 [22] 展示了如何进行仅旋转（3 DOF）姿态估计，[26] 则提出了一种适用于平面（2D）运动和平面场景的事件相机同步跟踪和映射算法。其他作者除了使用事件相机外，还使用了互补的传感模式： 文献[27]使用配备深度传感器的事件相机来联合估算相机姿态和三维场景结构，文献[13]提出了一种低延迟、基于特征的 6 DOF 视觉测距管道，该管道使用基于帧的传感器，在帧中检测特征，在事件流中跟踪特征。基于事件的 6DOF 视觉里程测量（仅使用事件相机）直到最近才首次出现： 文献[12]提出了三种并行滤波器，可联合估算摄像机姿态、场景三维地图和图像强度；文献[21]提出了一种几何方法，将全局图像配准技术与基于事件的重构算法[20]相结合，无需图像重构即可估算摄像机姿态和场景三维地图。**很少有研究考虑将事件相机与 IMU 结合使用（基于事件的视觉惯性里程测量问题）。[18] 展示了如何将事件和惯性测量融合到一个连续时间框架中。**然而，他们的方法并不适合实时使用，因为在接收到每个事件时都需要进行昂贵的优化来更新样条参数。最近，[28] 提出了一种基于事件的视觉惯性里程测量算法 EVIO，该算法可实时运行（尽管运动速度和特征数量有限）。**他们建议使用迭代期望最大化方案跟踪事件流中的一组特征，该方案可联合解决特征外观和光流问题。然后将特征轨迹输入 EKF 滤波器，以生成新的姿态估计值**。EVIO 是最接近这项工作的方法。在第 5 节中，我们将把我们的方法与 [28] 的准确性进行比较，结果表明我们的方法比 [28] 有显著提高。

在本文中，我们提出了一种新的视觉惯性里程（VIO）算法的事件相机。我们的算法作为输入的事件和惯性测量的流，并输出相机构成相机速度成比例的速率。为了实现这一点，我们跟踪事件中的一组特征，并使用基于关键帧的视觉惯性管道（使用非线性优化）将这些特征跟踪与IMU测量融合。

贡献我们的主要贡献是为事件摄像机提供了一个紧密耦合的视觉—惯性里程计管道，它比最先进的方法更精确[28]，同时也更高效。更准确地说，我们的贡献包括：

·用于事件相机的新颖特征跟踪器，其在事件帧上工作，通过使用相机运动和场景结构的当前估计在时空窗口中融合事件来合成。

·将这些特征轨迹集成在基于非线性优化的基于关键帧的视觉惯性流水线中，为事件摄像机提供强大而准确的VIO流水线。

·与公共事件摄像机数据集[19]上的最新技术[28]相比，我们的管道的定量评估，以及大规模和高速序列的一些定性结果。

## 3 Preliminaries

在本节中，我们将介绍我们将在本文的其余部分使用的符号。我们还介绍了惯性测量单元模型，并提供离散积分的运动方程的公式。

坐标框架符号。坐标框架 A 中的点 P 用位置向量 ArP 表示。帧与帧之间的变换用同调矩阵 TAB 表示，它将点从帧 B 变换到帧 A。我们的算法使用一个由事件相机和固定安装在一起的 IMU 组成的传感器。传感器主体相对于惯性世界帧 W 来表示。在惯性世界帧 W 中，我们将相机帧 C 和 IMU 传感器帧 S 区分开来。为了获得 TSC，必须对相机 + IMU 系统进行外部校准，例如使用 Kalibr 工具箱 [8]。

