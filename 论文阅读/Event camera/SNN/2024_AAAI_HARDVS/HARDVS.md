# HARDVS

## 摘要

目前主流的人体活动识别(HAR)算法都是基于RGB摄像机开发的，存在光照、运动速度快、隐私保护和能耗大等问题。同时，受生物启发的事件摄像机以其高动态范围、密集的时间分辨率和稀疏的空间分辨率、低延迟、低功耗等特点引起了人们的极大兴趣。由于它是一种新兴的传感器，甚至没有现实的大规模数据集。考虑到其巨大的实用价值，本文提出了一个包含300个类别和超过10万个事件序列的大规模基准数据集HARDVS来弥补这一差距。我们评估和报告了多种流行的HAR算法的性能，为未来的工作提供了广泛的基线以供比较。更重要的是，我们提出了一种新的时空特征学习和融合框架ESTF，用于基于事件流的人体活动识别。它首先使用Stemnet将事件流投影到空间和时间嵌入中，然后使用Transformer网络对双视图表示进行编码和融合。最后，将两个特征级联并送入分类头进行活动预测。在多个数据集上的大量实验充分验证了该模型的有效性。数据集和源代码都将在https://github.com/EventAHU/HARDVS.上发布

## 1.引言

随着智慧城市的快速发展，准确、高效地识别人类行为(即人类活动识别，HAR)成为一项迫在眉睫的任务。大多数研究人员开发了基于RGB相机的HAR算法[1，29]，这种相机部署广泛，易于收集数据。在大规模基准数据集[7，24，26，30，43，50，53]和深度学习的帮助下，对常规场景下的HAR进行了一定程度的研究。然而，由于RGB传感器的使用，监控视频集的存储、传输和分析限制了实际系统的需求。更详细地说，标准的RGB相机具有有限的帧速率(例如，30FPS)，这使得捕捉快速移动的对象变得困难，并且容易受到运动模糊的影响。较低的动态范围(60分贝)使RGB传感器在低照度下工作不佳。它还存在相邻帧之间的高冗余度，需要更多的存储和能量消耗。隐私保护也极大地限制了它的发展，因此，一个自然的问题是，我们必须识别使用RGB传感器的人类活动吗？

近年来，受到生物启发的传感器(称为事件摄像机)，如Davis[6]、CELEX[13]、ATIS[47]和PROPHESEE 1，引起了越来越多研究人员的关注。与以同步方式(即视频帧)记录光线的RGB相机不同，事件相机异步输出事件(或尖峰)，这与照明变化相对应。换句话说，只有当光线变化超过阈值时，事件摄像机的每个像素才会独立记录二进制值。用于增加和减少照度的事件分别被称为开事件和关事件。由于独特的采样机制，异步事件在空间上是稀疏的，但在时间上是密集的。它受运动模糊的影响较小，因此适合于捕捉快速移动的人类动作，如魔术师快速移动的手掌，以及运动运动员的运动识别。与标准RGB相机相比，它具有更高的动态范围(120分贝)和更低的延迟，这使得它即使在低照度下也能很好地工作。此外，存储和能耗也显著降低[21、34、58、67、68]。事件流突出了轮廓信息，在很大程度上保护了个人隐私。根据前面的观察和思考，我们受到启发，使用事件摄像机来解决野外人类活动识别问题。彩色相框和事件相机的成像原理的比较如图2所示。

虽然已经有几个基准数据集建议分类[2、5、28、30、33、49、53]。然而，它们中的大多数是由模拟器从RGB视频转换而来的模拟/合成数据集。一些研究人员通过在显示RGB视频的同时记录屏幕来获得事件数据。显然，这些数据集很难反映真实场景中事件摄像机的特征，特别是快速运动和微光场景。ASL-DVS[5]是由bi等人提出的。它由100,800个样本组成，但只能用于24个类别的手势识别。在深度学习时代，DvsGesture[2]也受到规模和品类的限制。此外，一些数据集的性能已经饱和，例如Wang等人。[57]在DvsGesture[2]数据集上已达到97.08%。因此，研究界对野外记录的大规模HAR基准数据集仍然有持续的需求。