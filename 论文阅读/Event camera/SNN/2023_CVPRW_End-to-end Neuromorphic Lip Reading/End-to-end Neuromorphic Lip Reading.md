# End-to-end Neuromorphic Lip Reading

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240214105041101.png" alt="image-20240214105041101" style="zoom:67%;" />

摘要：人类语言感知本质上是一种多模态任务，因为语言产生需要说话者的嘴唇运动，产生听觉信息之外的视觉线索。唇读指的是不借助声音，通过视觉上的唇动来理解语言。这是一项重要的任务，因为它既可以补充基于音频的语音识别系统，也可以在声音不可用时替代它。本文介绍了一种唇读的神经形态模型，该模型使用基于事件的传感器捕捉嘴唇运动产生的事件作为输入，并基于SNN结构将短事件序列分类为单词类别。实验结果表明，该模型成功地利用了神经形态学方法的各种优势，如能量效率和低延迟，这是实时嵌入式场景的核心特征。据我们所知，这是第一个端到端神经形态唇读模型的提议。

### 背景

最近，Tan et al.[33]提出了一种新的基于事件的唇读模型体系结构:MSTP网络。实验证明，MSTP在此任务上的性能优于目前最先进的基于事件的动作识别模型和基于视频的唇读模型。在MSTP网络中，输入的事件被转换成具有不同时间bin的低速率和高速率的事件帧，从而更好地保存事件流的时空信息。然后将这两种类型的事件帧输入到具有不同分支间消息流模块的多分支网络中，该模块设计用于从事件数据中感知完整的空间特征和精细的时间特征。接着，序列模型将视觉特征解码成文字。在他们的研究中，snn被提及，但由于缺乏有效的反向传播算法来训练它们而被丢弃。因此，snn还没有应用到这个问题上。

峰值神经网络:snn是由沃尔夫冈·马斯[25]首先在计算机科学中普及的生物启发学习模型。普通的神经网络是基于高度简化的大脑动力学的数学函数，而神经网络则试图通过精确定时发射电压“尖峰”来模仿生物神经元的行为。最常用的尖峰神经元模型是leaky - integration - fire (LIF)，该模型使用参数τ来调整膜电位向静息电位“泄漏”的速度。参数化的Leaky-Integrate-and-Fire 神经元(PLIF)对常规的LIF进行了有趣的变化，其中时间常数在训练期间进行了调整。这意味着，这些神经元细胞膜电位泄漏的速度不再是一个手工调节的参数。它们的膜电位按照公式1演化:

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240220105709527.png" alt="image-20240220105709527" style="zoom: 50%;" />

V[t]是t时刻的膜电位，Vreset是静息电位，X[t]是t时刻神经元的输入，τ是将要学习的时间常数。

由于尖峰神经元的尖峰函数不可微，snn不可能实现梯度下降。因此，训练这些网络是出了名的困难。直到最近几年，研究人员主要依赖于简单的学习机制(如STDP)，这对于监督学习来说往往是低效的，或者依赖于将一个常规的预先训练的神经网络转换成一个SNN。然而，最近的工作已经非常成功地找到了在snn中使用梯度下降的技巧和变通方法。Neftci et al.[27]描述了一种最流行的方法:在训练中使用可微的替代函数来代替不可微的spike激活函数。其中最突出的，我们可以引用分段二次函数，ATan，和高斯误差替代函数(Erf)，如图1所示。

> <img src="End-to-end Neuromorphic Lip Reading.assets/image-20240220110422158.png" alt="image-20240220110422158" style="zoom:50%;" />
>
> <img src="End-to-end Neuromorphic Lip Reading.assets/image-20240220110448984.png" alt="image-20240220110448984" style="zoom:50%;" />
>
> <img src="End-to-end Neuromorphic Lip Reading.assets/image-20240220110508004.png" alt="image-20240220110508004" style="zoom:50%;" />
>
> 图1。一些代理激活函数，来自SpikingJelly文档[13]。

这个代理函数是spike函数的近似，允许误差通过网络反向传播。因此，用snn就可以实现梯度下降。这种技术使得深度峰值网络在最近的现实生活问题(如汽车数据[8]中的物体识别)研究中可以与常规神经网络相媲美，有时甚至超过常规神经网络。不过，这种方法并没有充分利用snn的潜力，因为它也带来了常规ann所具有的一些约束(如网络层的单向信息流)。

随着代梯度下降法的普及，人们开始努力提供一种与常规 ANN 中使用的时间信息提取方法相当的尖峰神经元。线性递归尖峰神经元（Linearly recurrent spiking neurons）是具有递归线性连接的常规尖峰神经元，这种连接使其当前输出也取决于先前输出，其方式类似于 vanilla RNN。类似的方法还有尖峰 LSTM [24]，它被简化为尖峰门控递归单元（GRU）。在另一种方法中，**有状态突触[12]（stateful synapses）被置于尖峰层之后，通过累积输入尖峰电流提供额外记忆，使其输出取决于当前尖峰输入和之前的尖峰输入**。图 2 举例说明了这些突触在前一层出现一些尖峰时的行为。

这些突触也可以被视为漏整合神经元，它们不会发射尖峰脉冲，而只是输出膜电位。

在视觉应用中，**SNN 与基于事件的摄像头产生的异步事件链非常匹配**。从节能相机和学习模型的角度来看，SNN 对无人机或自动驾驶汽车等嵌入式系统非常有吸引力。在 Amir 等人[2]的大量研究中，SNN 已成功用于手势识别，显示了其在此类任务中的潜力。如前所述，最近在使用事件数据进行物体识别方面也取得了进展，如 Cordone 等人的研究[8]。几年前，SNN 还只能在非常简单的任务中勉强使用，而现在，它们在实际问题中的表现已与普通 ANN 不相上下。

> <img src="End-to-end Neuromorphic Lip Reading.assets/image-20240221104537929.png" alt="image-20240221104537929" style="zoom: 50%;" />
>
> 图2。有状态突触给出一些输入尖峰的输出，来自SpikingJelly文档[13]。

到目前为止，尽管snn具有吸引力，但仍未应用于自动唇读，这得到了上述论点的支持。因此，这项创新工作是第一个利用其优势在事件数据上进行唇读的特定任务。

### 建议的方法

如前所述，SNN的异步特性应该使它们与事件摄像机产生的事件数据完美匹配。但是，在代理梯度下降上下文中，有必要将数据转换为同步形式。

#### 3.1. 事件数据预处理

寻找表示事件数据的有效方法是一个难题，这本身就是先前研究的主题（如 [20]）。由于我们的目标是 DVS-Lip 数据集，因此我们选择使用与 [33] 所描述的方法类似的方法。在他们的研究中，作者将异步事件转换为三维阵列，即体素网格。我们数据集中的每个事件都用传感器上的 (x, y) 位置、时间 (t) 和极性 {-1, 1} 表示。等式 2 和 3（重用文献 [33]）显示了我们如何创建一个特定长度为 T 的体素网格，在该网格中，每个事件的极性通过两个最近的时空体素传播。

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240221110608990.png" alt="image-20240221110608990" style="zoom: 50%;" />

其中，T 是我们要使用的帧数（即网格的时间分辨率），tx 是原始视频中第 x 个事件的时间戳。通过对事件数据进行离散化处理，我们可以得到一个三维形状网格（t、x、y）。在 [33] 中，Tan 等人使用了两种不同的 T 值： 30 用于网络的低速率分支，210 用于高速率分支。然而，每个分支在未合并时的表现非常相似（低速分支和高速分支的准确率分别为 69.57% 和 69.49%）。只有将这两个分支与信息流模块块结合到多粒度网络中时，总体准确率才会提高到 72.10%。因此，我们决定使用 T = 30 进行实验，因为使用更大的值会大大降低训练过程的速度，而改进效果却微乎其微。

#### 3.2. 拓扑探索

据我们所知，之前没有工作使用snn对唇读的动态场景进行分类。此外，关于snn动态分类的文献很少。与我们的工作最接近的研究使用了[2]引入的DVS-Gesture数据集，以及相当简单的拓扑和不同的变体，如Yao等人的[35]。DVSGesture数据集本身相对容易分类，我们希望通过展示snn可以解决更困难的问题，为神经形态计算机视觉领域做出贡献。

我们测试了几种不同复杂程度的拓扑结构。一个好的起点是简单地重用一些在之前的工作中提出的简单拓扑，尝试对DVS-Gesture进行分类，或者用于其他视觉任务，如事件-视频重建[37]。我们使用了Yao等人的拓扑。图3显示了我们使用的两种简单SNN拓扑;我们将这些模型称为SNN1和SNN2。

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240221112155664.png" alt="image-20240221112155664" style="zoom: 50%;" />

SNN1借鉴了[35]，[35]最初设计了这种拓扑来对DVS-Gesture进行分类。SNN2的灵感来自Zhu等人的[37]，其中作者使用尖峰编码器和解码器架构进行事件视频重建。SNN2是他们模型的编码器部分，其中的残差层被另外两个卷积层所取代，从而产生更高的精度。在每次卷积之后都添加了批处理归一化层，因为这些层已经被证明可以大大促进学习过程。在这个主题上，[8]表明，在使用复杂snn时，批处理归一化层是至关重要的，并报告了在不使用批处理归一化时，性能显著下降，或者网络根本无法学习。

除了这些简单的模型，我们还设计了一个相当于 MSTP 低速率分支的尖峰模型。由于该模型使用 ResNet [22] 作为骨干网，我们首先以类似于 Fang 等人 [14] 的方式实现了一个尖峰 ResNet 骨干网，然后应用了 MSTP 架构。我们的尖峰 MSTP 低速率分支的拓扑结构如图 4 所示。与之前介绍的基本 SNN 相比，这里不需要添加批处理归一化层，因为基本模型已经具备这些功能。总的来说，我们对原始模型几乎没有做任何修改，最终得到的尖峰低速率分支 MSTP 与文献 [14] 中介绍的尖峰要素明智 ResNet (SEWResNet) 非常相似。

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240221112301363.png" alt="image-20240221112301363" style="zoom: 50%;" />

**我们对 MSTP 的尖峰适应与原始模型的一个关键区别在于，我们在架构的输出端附近使用了 GRU 层。**一般来说，当需要从时间序列中提取信息时，通常会使用 RNN。其输出取决于当前输入和隐藏状态。特别是 Chung 等人提出的 GRU [5]，允许每个神经元学习需要遗忘多少之前的信息，以及需要记忆多少当前的新输入。虽然 Rezaabad 等人[24]提出了尖峰 LSTM 层（可调整为尖峰 GRU），但我们发现它在我们的案例中效果非常不理想。特别是当我们试图坚持使用 MSTP 中最初的 3 层双向 GRU 时，我们的网络表现出了非常缓慢和低效的学习过程，因此我们最终决定尝试寻找其他方法来提取时间信息。在下一节中，我们将进一步详细介绍我们尝试使用哪些技术来替代 GRU 层。

#### 3.3. 实验

我们在 DVSLip 数据集上进行了 SNN 实验，使用了 30 个时间步（公式 2 中的 T = 30），目的是帮助我们找到最有前途的尖峰拓扑，然后再将 MSTP 与最佳 SNN 进行比较。我们使用了参数泄漏-积分-火灾神经元[15]（PLIF）和学习率为 1e-3 的亚当优化器，并使用余弦退火调度器在训练过程中调整学习率，其方式与 Cordone 等人的研究类似[8]。神经元参数见表 1。1 利用这些设置，我们围绕以下 3 点进行了实验。

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240221190619582.png" alt="image-20240221190619582" style="zoom:50%;" />

1 - 首先，我们在小规模实验中比较了之前介绍的代用激活函数。如前所述，**代用梯度下降需要选择一个激活函数来替代尖峰神经元使用的常规无差异阶跃函数。**为了选出最有前途的激活函数，我们使用最小的网络（SNN1）在 DVS-Lip 数据集的 10 个单词子集上进行了 50 个历时的快速测试运行。

2 - 然后，我们使用在之前实验中取得最佳结果的代理函数，比较了每个拓扑结构的性能。尽管我们怀疑我们的尖峰 MSTP 分支性能最好，但我们仍想尝试基本模型，以建立尖峰基线。因此，我们在完整的 DVS-Lip 数据集上对每个拓扑进行了 100 个历时的训练。

3 - 最后，我们进行了一项消融研究，以在尖峰适应中调整 MSTP 的 GRU 层。如前所述，使用改编自文献[24]的 3 层双向尖峰 GRU 得到的结果并不理想。使用 GRU 的目的是帮助提取时间信息，但也有其他方法可以做到这一点。我们测试了之前介绍过的**线性递归尖峰神经元和有状态突触**。我们**还尝试用简单的全连接尖峰神经元层取代 GRU 层。**每种替代方法都测试了 100 个历时。

所有实验都是在一台笔记本电脑上运行的，它配备了英特尔酷睿i9-12950HX CPU (2.5 GHz x 16)， 62,5 GB RAM, NVIDIA RTX A5500笔记本电脑GPU和16 GB VRAM。

### 实验结果

#### 4.1. 拓扑结果

我们在这里讨论了使用各种snn拓扑和超参数对DVS-Lip数据集进行分类的实验结果。首先，表2显示了我们第一批训练的结果，这是为了帮助我们选择一个代理激活函数用于接下来的工作。

> <img src="End-to-end Neuromorphic Lip Reading.assets/image-20240226150147734.png" alt="image-20240226150147734" style="zoom:50%;" />
>
> 表 2. SNN1 在 DVSLip 的 10 个类别子集上使用不同代理函数的准确率。这些类别对应的单词有：allow、allowed、America、American、benefit、benefits、billion、called、challenge 和 change。

代用函数的选择会极大地影响网络的性能。初步测试表明，Erf 的性能略优于 ATan 和 Piecewise，因此我们在接下来的实验中继续使用 Erf。

在这些初步测试之后，我们测试了前面介绍的3种拓扑，看看哪一种性能最好。表3显示了它们各自的性能。

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240226150515619.png" alt="image-20240226150515619" style="zoom: 50%;" />

第二批实验表明，与其他模型(SNN1和SNN2)相比，尖峰MSTP获得了明显更好的结果。

#### 4.2. 消融研究结果

在这一阶段，尖峰 MSTP 没有使用任何递归层，只是用一个尖峰全连接层取代了原来的 GRU。**我们对可能的 GRU 替换进行了实验，以了解是否可以通过使用其他时间信息提取方法获得更高的性能**，如上一节所述。<u>表 4</u> 列出了第三批实验的结果，以及使用 SNN 对 DVS-Lip 数据集的最终准确率。

> <img src="End-to-end Neuromorphic Lip Reading.assets/image-20240226152404765.png" alt="image-20240226152404765" style="zoom:50%;" />
>
> 表4.对整个DVS-Lip数据集的MSTP结果进行Spiking，在分类部分尝试对3层双向GRU进行不同的替换。

该表显示，通过使用**有状态突触**替代GRU层，可以获得显著的性能增长。我们还包括[33]中发布的原始MSTP的准确性，它仍然高于我们最好的峰值模型。表5显示了MSTP的精度和大小、仅MSTP的低速率分支和不含三层双向GRU的MSTP的低速率分支。

<img src="End-to-end Neuromorphic Lip Reading.assets/image-20240226153305392.png" alt="image-20240226153305392" style="zoom:50%;" />

在<u>最后一个表中</u>，我们可以观察到，尽管我们的模型需要的内存量不到MSTP的5倍，但它仍然能够保持其准确率的83%。此外，**我们的模型与mstp的低速率分支之间的主要拓扑差异是没有3层双向GRU**。如果删除，**MSTP的低速率分支现在与我们的模型大小相同，但精度略低**。最后，我们模型的尖峰特性可以使其成为嵌入式系统的一个有趣的选择，在嵌入式系统中，我们较低的精度仍然可以被视为更节能模型的一个很好的权衡。

### 结论

本文提出了第一个基于事件的唇读SNN模型，并给出了与当前人工神经网络技术的竞争结果。我们展示了如何使用各种代理函数测试几种拓扑，**并使用有状态突触改进基本结果**，以提取更多的时间信息。我们的模型是第一个先进的深脉冲模型应用于这样一个具有挑战性的任务，并设法获得有希望的结果，同时保持相对较小的尺寸。

在不久的将来，进一步改进数据预处理和SNN模型本身的实验可能会使最先进的模型得以实现。在没有针对类似任务的深度和复杂snn发表的情况下，我们希望为该领域的未来工作提供一个峰值基线。

**我们认为我们最终的SNN还可以改进，特别是关于我们从MSTP替换GRU层的方式。我们的状态突触允许我们打破60%的准确率线，但我们仍然认为MSTP和该模型之间的大部分性能差距在于这种替换。**寻找更有效的方法从数据的时间成分中提取信息可能是未来工作的一个很好的方向。此外，尽管我们认为代理梯度下降是目前snn监督学习的最佳训练方法，但结果还可以改进。通过这种强制梯度下降的方式，我们给我们的snn带来了很多常规ANN的局限性，同时在训练过程中也使用了很多近似。因此，我们希望将来能发展出其他训练方法，使我们能够充分发挥snn的潜力。

尽管所提出的模型的准确性低于目前最先进的模型，但我们仍然表明snn可以用于复杂的视频分类任务，因为唇读即使对人类来说也是非常具有挑战性的。此外，我们的工作为该领域的未来研究提供了有价值的见解，因为我们提出了第一个自动唇读的SNN模型。我们的工作还表明，代理梯度下降确实为snn的监督训练提供了一个有价值的选择，我们最终的峰值模型显示了与常规深度人工神经网络具有竞争结果的潜力。



