# 事件相机目标检测类数据集

1. #### [NeurIPS 2020](https://paperswithcode.com/conference/neurips-2020-12) Learning to Detect Objects with a 1 Megapixel Event Camera 

​	<https://paperswithcode.com/paper/learning-to-detect-objects-with-a-1-megapixel>

​	在本文中，首先，我们公开发布第一个高分辨率大规模数据集以进行对象检测。该数据集包含1兆像素事件摄像头的14小时以上的录音，以及25m框架的汽车，行人和两轮车，并以高频标记。

2. #### CVPRW 2023 PEDRo: an Event-based Dataset for Person Detection in Robotics 

​	<https://github.com/SSIGPRO/PEDRo-Event-Based-Dataset>

​	PEDRO事件数据集是专门为服务机器人技术检测而设计的。该数据集是通过在各种场景和照明条件下使用移动的Davis346活动摄像头收集的。

​	该数据集由：

- 119张记录，平均持续时间为18秒。
- 43 259手动注释的边界框。
- 27000个40毫秒的样品。

​	该数据集专注于人员，使其与其他基于事件的数据集成为处理人检测任务的相关补充。PEDRO数据集可以在此处下载。

3. #### [EventVOT_Benchmark](https://github.com/Event-AHU/EventVOT_Benchmark)  Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric

​	<https://github.com/Event-AHU/COESOT>	

​	结合色彩和事件相机（又称动态视觉传感器，DVS）进行鲁棒性物体跟踪是近年来新出现的研究课题。现有的颜色-事件跟踪框架通常包含多个分散的模块，可能导致效率低、计算复杂度高，包括特征提取、融合、匹配、交互式学习等。本文提出了一种单级骨干网络色彩事件统一跟踪（CEUTrack），可同时实现上述功能。给定事件点和 RGB 帧后，我们首先将点转换为体素，并分别裁剪出两种模式的模板区域和搜索区域。然后，将这些区域投影成标记，并平行输入统一的 Transformer 骨干网络。输出的特征将输入跟踪头，用于目标对象定位。我们提出的 CEUTrack 简单、有效、高效，可实现超过 75 FPS 的速度和全新的 SOTA 性能。为了更好地验证我们模型的有效性并解决该任务数据不足的问题，我们还提出了一个通用的大规模色彩事件跟踪基准数据集，称为 COESOT，其中包含 90 个类别和 1354 个视频序列。此外，我们还在评估工具包中提出了一个名为 BOC 的新评估指标，用于评估相对于基准方法的突出性。我们希望新提出的方法、数据集和评价指标能为基于颜色事件的跟踪提供一个更好的平台。

​	Demo video for EventVOT dataset <https://www.youtube.com/watch?v=FcwH7tkSXK0>

4. #### Frontiers in neurorobotics, 2019 Neuromorphic Vision Datasets for Pedestrian Detection, Action Recognition, and Fall Detection

​	<https://github.com/CrystalMiaoshu/PAFBenchmark>

​	通过SAE编码方法，将大部分行人检测原始数据转换为4670帧图像，帧间隔为20ms。在我们的实验中，所有这些图像都通过标注工具labelImg进行了标注。

5. #### CVPRW 2021 DVS-OUTLAB: A Neuromorphic Event-Based Long Time Monitoring Dataset for Real-World Outdoor Scenarios

​	神经形态视觉传感器是具有生物学启发的设备，与众所周知的基于框架的传感器有不同。尽管该研究领域的发展正在增加，但完全依赖事件摄像机的应用程序仍然相对罕见。除了实验室条件之外，考虑到实际室外场景时，这一点尤其清楚。在这种情况下，基于事件的视力应用程序开发的一个障碍可能是缺乏用于算法开发和评估的标签数据集。因此，我们描述了基于DVS的长时间监控城市公共区域的录音设置，并提供标记的DVS数据，该数据还包含了此过程中记录的环境室外影响的影响。我们还描述了用于标签生成的加工链，以及使用各种时空事件流过滤器进行的授权基准的结果。该数据集包含近7个小时的现实世界户外事件数据，并具有≈47K的景点和约当的贴标签区域。可以在http://dnt.kr.hsnr.de/DVS-OUTLAB/下载

6. #### *arXiv*, Jan. 2020 A Large Scale Event-based Detection Dataset for Automotive

​	<https://www.prophesee.ai/2020/01/24/prophesee-gen1-automotive-detection-dataset/>	

​	我们介绍了第一个用于事件摄像机的非常大的检测数据集。该数据集由使用304x240 ATIS传感器获取的超过39个小时的汽车记录组成。它包含开放的道路和非常多样化的驾驶场景，包括城市，高速公路，郊区和乡村场景，以及不同的天气和照明条件。记录中包含的汽车和行人的手动边界框注释也以1到4Hz的频率提供，总共产生了超过255,000个标签。我们认为，此大小标记的数据集的可用性将有助于基于事件的视力任务（例如对象检测和分类）的重大进展。我们还期望在其他任务中的好处，例如光流，运动和跟踪的结构，例如，可以通过自我监督的学习方法利用大量数据。

